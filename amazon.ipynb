{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data set and fist insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./amazon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>category</th>\n",
       "      <th>discounted_price</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>discount_percentage</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>about_product</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_content</th>\n",
       "      <th>img_link</th>\n",
       "      <th>product_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B07JW9H4J1</td>\n",
       "      <td>Wayona Nylon Braided USB to Lightning Fast Cha...</td>\n",
       "      <td>Computers&amp;Accessories|Accessories&amp;Peripherals|...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>₹1,099</td>\n",
       "      <td>64%</td>\n",
       "      <td>4.2</td>\n",
       "      <td>24,269</td>\n",
       "      <td>High Compatibility : Compatible With iPhone 12...</td>\n",
       "      <td>AG3D6O4STAQKAY2UVGEUV46KN35Q,AHMY5CWJMMK5BJRBB...</td>\n",
       "      <td>Manav,Adarsh gupta,Sundeep,S.Sayeed Ahmed,jasp...</td>\n",
       "      <td>R3HXWT0LRP0NMF,R2AJM3LFTLZHFO,R6AQJGUP6P86,R1K...</td>\n",
       "      <td>Satisfied,Charging is really fast,Value for mo...</td>\n",
       "      <td>Looks durable Charging is fine tooNo complains...</td>\n",
       "      <td>https://m.media-amazon.com/images/W/WEBP_40237...</td>\n",
       "      <td>https://www.amazon.in/Wayona-Braided-WN3LG1-Sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B098NS6PVG</td>\n",
       "      <td>Ambrane Unbreakable 60W / 3A Fast Charging 1.5...</td>\n",
       "      <td>Computers&amp;Accessories|Accessories&amp;Peripherals|...</td>\n",
       "      <td>₹199</td>\n",
       "      <td>₹349</td>\n",
       "      <td>43%</td>\n",
       "      <td>4.0</td>\n",
       "      <td>43,994</td>\n",
       "      <td>Compatible with all Type C enabled devices, be...</td>\n",
       "      <td>AECPFYFQVRUWC3KGNLJIOREFP5LQ,AGYYVPDD7YG7FYNBX...</td>\n",
       "      <td>ArdKn,Nirbhay kumar,Sagar Viswanathan,Asp,Plac...</td>\n",
       "      <td>RGIQEG07R9HS2,R1SMWZQ86XIN8U,R2J3Y1WL29GWDE,RY...</td>\n",
       "      <td>A Good Braided Cable for Your Type C Device,Go...</td>\n",
       "      <td>I ordered this cable to connect my phone to An...</td>\n",
       "      <td>https://m.media-amazon.com/images/W/WEBP_40237...</td>\n",
       "      <td>https://www.amazon.in/Ambrane-Unbreakable-Char...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B096MSW6CT</td>\n",
       "      <td>Sounce Fast Phone Charging Cable &amp; Data Sync U...</td>\n",
       "      <td>Computers&amp;Accessories|Accessories&amp;Peripherals|...</td>\n",
       "      <td>₹199</td>\n",
       "      <td>₹1,899</td>\n",
       "      <td>90%</td>\n",
       "      <td>3.9</td>\n",
       "      <td>7,928</td>\n",
       "      <td>【 Fast Charger&amp; Data Sync】-With built-in safet...</td>\n",
       "      <td>AGU3BBQ2V2DDAMOAKGFAWDDQ6QHA,AESFLDV2PT363T2AQ...</td>\n",
       "      <td>Kunal,Himanshu,viswanath,sai niharka,saqib mal...</td>\n",
       "      <td>R3J3EQQ9TZI5ZJ,R3E7WBGK7ID0KV,RWU79XKQ6I1QF,R2...</td>\n",
       "      <td>Good speed for earlier versions,Good Product,W...</td>\n",
       "      <td>Not quite durable and sturdy,https://m.media-a...</td>\n",
       "      <td>https://m.media-amazon.com/images/W/WEBP_40237...</td>\n",
       "      <td>https://www.amazon.in/Sounce-iPhone-Charging-C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08HDJ86NZ</td>\n",
       "      <td>boAt Deuce USB 300 2 in 1 Type-C &amp; Micro USB S...</td>\n",
       "      <td>Computers&amp;Accessories|Accessories&amp;Peripherals|...</td>\n",
       "      <td>₹329</td>\n",
       "      <td>₹699</td>\n",
       "      <td>53%</td>\n",
       "      <td>4.2</td>\n",
       "      <td>94,363</td>\n",
       "      <td>The boAt Deuce USB 300 2 in 1 cable is compati...</td>\n",
       "      <td>AEWAZDZZJLQUYVOVGBEUKSLXHQ5A,AG5HTSFRRE6NL3M5S...</td>\n",
       "      <td>Omkar dhale,JD,HEMALATHA,Ajwadh a.,amar singh ...</td>\n",
       "      <td>R3EEUZKKK9J36I,R3HJVYCLYOY554,REDECAZ7AMPQC,R1...</td>\n",
       "      <td>Good product,Good one,Nice,Really nice product...</td>\n",
       "      <td>Good product,long wire,Charges good,Nice,I bou...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41V5FtEWPk...</td>\n",
       "      <td>https://www.amazon.in/Deuce-300-Resistant-Tang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B08CF3B7N1</td>\n",
       "      <td>Portronics Konnect L 1.2M Fast Charging 3A 8 P...</td>\n",
       "      <td>Computers&amp;Accessories|Accessories&amp;Peripherals|...</td>\n",
       "      <td>₹154</td>\n",
       "      <td>₹399</td>\n",
       "      <td>61%</td>\n",
       "      <td>4.2</td>\n",
       "      <td>16,905</td>\n",
       "      <td>[CHARGE &amp; SYNC FUNCTION]- This cable comes wit...</td>\n",
       "      <td>AE3Q6KSUK5P75D5HFYHCRAOLODSA,AFUGIFH5ZAFXRDSZH...</td>\n",
       "      <td>rahuls6099,Swasat Borah,Ajay Wadke,Pranali,RVK...</td>\n",
       "      <td>R1BP4L2HH9TFUP,R16PVJEXKV6QZS,R2UPDB81N66T4P,R...</td>\n",
       "      <td>As good as original,Decent,Good one for second...</td>\n",
       "      <td>Bought this instead of original apple, does th...</td>\n",
       "      <td>https://m.media-amazon.com/images/W/WEBP_40237...</td>\n",
       "      <td>https://www.amazon.in/Portronics-Konnect-POR-1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                       product_name  \\\n",
       "0  B07JW9H4J1  Wayona Nylon Braided USB to Lightning Fast Cha...   \n",
       "1  B098NS6PVG  Ambrane Unbreakable 60W / 3A Fast Charging 1.5...   \n",
       "2  B096MSW6CT  Sounce Fast Phone Charging Cable & Data Sync U...   \n",
       "3  B08HDJ86NZ  boAt Deuce USB 300 2 in 1 Type-C & Micro USB S...   \n",
       "4  B08CF3B7N1  Portronics Konnect L 1.2M Fast Charging 3A 8 P...   \n",
       "\n",
       "                                            category discounted_price  \\\n",
       "0  Computers&Accessories|Accessories&Peripherals|...             ₹399   \n",
       "1  Computers&Accessories|Accessories&Peripherals|...             ₹199   \n",
       "2  Computers&Accessories|Accessories&Peripherals|...             ₹199   \n",
       "3  Computers&Accessories|Accessories&Peripherals|...             ₹329   \n",
       "4  Computers&Accessories|Accessories&Peripherals|...             ₹154   \n",
       "\n",
       "  actual_price discount_percentage rating rating_count  \\\n",
       "0       ₹1,099                 64%    4.2       24,269   \n",
       "1         ₹349                 43%    4.0       43,994   \n",
       "2       ₹1,899                 90%    3.9        7,928   \n",
       "3         ₹699                 53%    4.2       94,363   \n",
       "4         ₹399                 61%    4.2       16,905   \n",
       "\n",
       "                                       about_product  \\\n",
       "0  High Compatibility : Compatible With iPhone 12...   \n",
       "1  Compatible with all Type C enabled devices, be...   \n",
       "2  【 Fast Charger& Data Sync】-With built-in safet...   \n",
       "3  The boAt Deuce USB 300 2 in 1 cable is compati...   \n",
       "4  [CHARGE & SYNC FUNCTION]- This cable comes wit...   \n",
       "\n",
       "                                             user_id  \\\n",
       "0  AG3D6O4STAQKAY2UVGEUV46KN35Q,AHMY5CWJMMK5BJRBB...   \n",
       "1  AECPFYFQVRUWC3KGNLJIOREFP5LQ,AGYYVPDD7YG7FYNBX...   \n",
       "2  AGU3BBQ2V2DDAMOAKGFAWDDQ6QHA,AESFLDV2PT363T2AQ...   \n",
       "3  AEWAZDZZJLQUYVOVGBEUKSLXHQ5A,AG5HTSFRRE6NL3M5S...   \n",
       "4  AE3Q6KSUK5P75D5HFYHCRAOLODSA,AFUGIFH5ZAFXRDSZH...   \n",
       "\n",
       "                                           user_name  \\\n",
       "0  Manav,Adarsh gupta,Sundeep,S.Sayeed Ahmed,jasp...   \n",
       "1  ArdKn,Nirbhay kumar,Sagar Viswanathan,Asp,Plac...   \n",
       "2  Kunal,Himanshu,viswanath,sai niharka,saqib mal...   \n",
       "3  Omkar dhale,JD,HEMALATHA,Ajwadh a.,amar singh ...   \n",
       "4  rahuls6099,Swasat Borah,Ajay Wadke,Pranali,RVK...   \n",
       "\n",
       "                                           review_id  \\\n",
       "0  R3HXWT0LRP0NMF,R2AJM3LFTLZHFO,R6AQJGUP6P86,R1K...   \n",
       "1  RGIQEG07R9HS2,R1SMWZQ86XIN8U,R2J3Y1WL29GWDE,RY...   \n",
       "2  R3J3EQQ9TZI5ZJ,R3E7WBGK7ID0KV,RWU79XKQ6I1QF,R2...   \n",
       "3  R3EEUZKKK9J36I,R3HJVYCLYOY554,REDECAZ7AMPQC,R1...   \n",
       "4  R1BP4L2HH9TFUP,R16PVJEXKV6QZS,R2UPDB81N66T4P,R...   \n",
       "\n",
       "                                        review_title  \\\n",
       "0  Satisfied,Charging is really fast,Value for mo...   \n",
       "1  A Good Braided Cable for Your Type C Device,Go...   \n",
       "2  Good speed for earlier versions,Good Product,W...   \n",
       "3  Good product,Good one,Nice,Really nice product...   \n",
       "4  As good as original,Decent,Good one for second...   \n",
       "\n",
       "                                      review_content  \\\n",
       "0  Looks durable Charging is fine tooNo complains...   \n",
       "1  I ordered this cable to connect my phone to An...   \n",
       "2  Not quite durable and sturdy,https://m.media-a...   \n",
       "3  Good product,long wire,Charges good,Nice,I bou...   \n",
       "4  Bought this instead of original apple, does th...   \n",
       "\n",
       "                                            img_link  \\\n",
       "0  https://m.media-amazon.com/images/W/WEBP_40237...   \n",
       "1  https://m.media-amazon.com/images/W/WEBP_40237...   \n",
       "2  https://m.media-amazon.com/images/W/WEBP_40237...   \n",
       "3  https://m.media-amazon.com/images/I/41V5FtEWPk...   \n",
       "4  https://m.media-amazon.com/images/W/WEBP_40237...   \n",
       "\n",
       "                                        product_link  \n",
       "0  https://www.amazon.in/Wayona-Braided-WN3LG1-Sy...  \n",
       "1  https://www.amazon.in/Ambrane-Unbreakable-Char...  \n",
       "2  https://www.amazon.in/Sounce-iPhone-Charging-C...  \n",
       "3  https://www.amazon.in/Deuce-300-Resistant-Tang...  \n",
       "4  https://www.amazon.in/Portronics-Konnect-POR-1...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1465, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1465 entries, 0 to 1464\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   product_id           1465 non-null   object\n",
      " 1   product_name         1465 non-null   object\n",
      " 2   category             1465 non-null   object\n",
      " 3   discounted_price     1465 non-null   object\n",
      " 4   actual_price         1465 non-null   object\n",
      " 5   discount_percentage  1465 non-null   object\n",
      " 6   rating               1465 non-null   object\n",
      " 7   rating_count         1463 non-null   object\n",
      " 8   about_product        1465 non-null   object\n",
      " 9   user_id              1465 non-null   object\n",
      " 10  user_name            1465 non-null   object\n",
      " 11  review_id            1465 non-null   object\n",
      " 12  review_title         1465 non-null   object\n",
      " 13  review_content       1465 non-null   object\n",
      " 14  img_link             1465 non-null   object\n",
      " 15  product_link         1465 non-null   object\n",
      "dtypes: object(16)\n",
      "memory usage: 183.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first check for the unique product values and drop duplicates if they exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.product_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the data set has 1465 it has some duplicated products. Let's drop its.\n",
    "uniques = df.product_id.drop_duplicates().index\n",
    "df = df.iloc[uniques].reset_index().drop(columns = [\"index\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now will look for nulls over the three columns to use rating count, product name and about product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1349\n",
       "True        2\n",
       "Name: rating_count, dtype: int64"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rating_count.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete Nan values in rating_count with 0\n",
    "df.rating_count.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1351\n",
       "Name: product_name, dtype: int64"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.product_name.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1351\n",
       "Name: about_product, dtype: int64"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.about_product.isna().value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set column to be used on classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will set a product as bestseller when the sales are above 0.90 quartile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salesToInt(x):\n",
    "    if \",\" in str(x):\n",
    "        int_split = x.split(\",\")\n",
    "        return int(int_split[0]+int_split[1])\n",
    "    \n",
    "    return int(x)\n",
    "\n",
    "df[\"sales\"] = df.rating_count.apply(lambda x : salesToInt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "quartile = int(df['sales'].quantile([0.90]).iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function set a quality value based on rating\n",
    "def setCategorization(sales, quartile):\n",
    "    \n",
    "    if sales >= quartile:\n",
    "        return 1 # Best sellers\n",
    "    \n",
    "    return 0 # regular\n",
    "\n",
    "# save quality value on a new column \"quality\"\n",
    "df[\"product_category\"] = df.sales.apply(lambda x: setCategorization(x, quartile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1214\n",
       "1     137\n",
       "Name: product_category, dtype: int64"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"product_category\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also create a single field with both product name and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"] = df.product_name + \"|\" + df.about_product"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move trought the model with a Tensorflow Keras tokenizer. It will first building a vocabulary of all unique words in the text data. Then, each word is assigned a unique integer value. The Tokenizer then replaces each word in the text with its corresponding integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intializing keras tokenizer\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[\"description\"]\n",
    "y = df[\"product_category\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8, random_state=1901)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all parameter\n",
    "num_words = 5000\n",
    "embedding_dim = 16\n",
    "maxlen = 150\n",
    "truncating = 'post'\n",
    "oov_token = '<OOV>'\n",
    "padding_type = 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the tokenizer for x_train\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "padded = pad_sequences(sequences, maxlen=maxlen, truncating=truncating)\n",
    "testing_sentences = tokenizer.texts_to_sequences(X_test)\n",
    "testing_padded = pad_sequences(testing_sentences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize LSTM with three hidden layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(num_words,  embedding_dim, input_length=maxlen), # Add an embedding layer that learns a dense vector representation for each word\n",
    "    tf.keras.layers.LSTM(64, dropout=0.1,use_bias = False), \n",
    "    # Add 3 hidden layer alternating the activation method\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='tanh'),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"), \n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a loss, optimizer and metric\n",
    "model.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_30 (Embedding)    (None, 150, 16)           80000     \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 64)                20480     \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 64)                1088      \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,505\n",
      "Trainable params: 119,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train and y_test to array\n",
    "y_train_arr = np.array(y_train)\n",
    "y_test_arr = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "34/34 [==============================] - 3s 36ms/step - loss: 0.5093 - accuracy: 0.8880 - val_loss: 0.2968 - val_accuracy: 0.9114\n",
      "Epoch 2/10000\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.3191 - accuracy: 0.8954 - val_loss: 0.2874 - val_accuracy: 0.9114\n",
      "Epoch 3/10000\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.3232 - accuracy: 0.8954 - val_loss: 0.2798 - val_accuracy: 0.9114\n",
      "Epoch 4/10000\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.1902 - accuracy: 0.9019 - val_loss: 0.3085 - val_accuracy: 0.8856\n",
      "Epoch 5/10000\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.0967 - accuracy: 0.9676 - val_loss: 0.4160 - val_accuracy: 0.8598\n",
      "Epoch 6/10000\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0419 - accuracy: 0.9861 - val_loss: 0.5335 - val_accuracy: 0.8856\n",
      "Epoch 7/10000\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0290 - accuracy: 0.9917 - val_loss: 0.5275 - val_accuracy: 0.8524\n",
      "Epoch 8/10000\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0361 - accuracy: 0.9907 - val_loss: 0.5263 - val_accuracy: 0.8782\n",
      "Epoch 9/10000\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0293 - accuracy: 0.9907 - val_loss: 0.5192 - val_accuracy: 0.8745\n",
      "Epoch 10/10000\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.6144 - val_accuracy: 0.8893\n",
      "Epoch 11/10000\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0249 - accuracy: 0.9935 - val_loss: 0.5874 - val_accuracy: 0.8819\n",
      "Epoch 12/10000\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0189 - accuracy: 0.9935 - val_loss: 0.6136 - val_accuracy: 0.8856\n",
      "Epoch 13/10000\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.6400 - val_accuracy: 0.8893\n",
      "Epoch 14/10000\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0173 - accuracy: 0.9935 - val_loss: 0.5848 - val_accuracy: 0.8819\n",
      "Epoch 15/10000\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0199 - accuracy: 0.9935 - val_loss: 0.5288 - val_accuracy: 0.8672\n",
      "Epoch 16/10000\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.5403 - val_accuracy: 0.8672\n",
      "Epoch 17/10000\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.6442 - val_accuracy: 0.8893\n",
      "Epoch 18/10000\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.5996 - val_accuracy: 0.8856\n",
      "Epoch 19/10000\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.6101 - val_accuracy: 0.8708\n",
      "Epoch 20/10000\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0080 - accuracy: 0.9963 - val_loss: 0.6956 - val_accuracy: 0.8856\n",
      "Epoch 21/10000\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.6670 - val_accuracy: 0.8672\n",
      "Epoch 22/10000\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.7029 - val_accuracy: 0.8856\n",
      "Epoch 23/10000\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9270 - val_accuracy: 0.9188\n",
      "Epoch 24/10000\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.7405 - val_accuracy: 0.8893\n",
      "Epoch 25/10000\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.8354 - val_accuracy: 0.9077\n",
      "Epoch 26/10000\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.7129 - val_accuracy: 0.8745\n",
      "Epoch 27/10000\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.7345 - val_accuracy: 0.8782\n",
      "Epoch 28/10000\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 0.7744 - val_accuracy: 0.8819\n",
      "Epoch 29/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.7825 - val_accuracy: 0.8930\n",
      "Epoch 30/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.4029e-04 - accuracy: 1.0000 - val_loss: 0.7839 - val_accuracy: 0.8967\n",
      "Epoch 31/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 7.5121e-04 - accuracy: 1.0000 - val_loss: 0.8010 - val_accuracy: 0.8856\n",
      "Epoch 32/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.8715e-04 - accuracy: 1.0000 - val_loss: 0.8338 - val_accuracy: 0.8893\n",
      "Epoch 33/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.1077e-04 - accuracy: 1.0000 - val_loss: 0.8523 - val_accuracy: 0.9041\n",
      "Epoch 34/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.0959e-04 - accuracy: 1.0000 - val_loss: 0.8734 - val_accuracy: 0.9041\n",
      "Epoch 35/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 6.8772e-05 - accuracy: 1.0000 - val_loss: 0.8902 - val_accuracy: 0.9041\n",
      "Epoch 36/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.8079e-05 - accuracy: 1.0000 - val_loss: 0.9018 - val_accuracy: 0.9041\n",
      "Epoch 37/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.7535e-05 - accuracy: 1.0000 - val_loss: 0.9094 - val_accuracy: 0.9004\n",
      "Epoch 38/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.5613e-05 - accuracy: 1.0000 - val_loss: 0.9179 - val_accuracy: 0.9004\n",
      "Epoch 39/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.8912e-05 - accuracy: 1.0000 - val_loss: 0.9265 - val_accuracy: 0.9004\n",
      "Epoch 40/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.5606e-05 - accuracy: 1.0000 - val_loss: 0.9337 - val_accuracy: 0.9004\n",
      "Epoch 41/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.3755e-05 - accuracy: 1.0000 - val_loss: 0.9398 - val_accuracy: 0.9004\n",
      "Epoch 42/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.0716e-05 - accuracy: 1.0000 - val_loss: 0.9477 - val_accuracy: 0.9004\n",
      "Epoch 43/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.7890e-05 - accuracy: 1.0000 - val_loss: 0.9527 - val_accuracy: 0.9004\n",
      "Epoch 44/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.1993e-05 - accuracy: 1.0000 - val_loss: 0.9557 - val_accuracy: 0.9004\n",
      "Epoch 45/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.4692e-05 - accuracy: 1.0000 - val_loss: 0.9598 - val_accuracy: 0.9004\n",
      "Epoch 46/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.3534e-05 - accuracy: 1.0000 - val_loss: 0.9639 - val_accuracy: 0.9004\n",
      "Epoch 47/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.6236e-05 - accuracy: 1.0000 - val_loss: 0.9683 - val_accuracy: 0.9004\n",
      "Epoch 48/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.2973e-05 - accuracy: 1.0000 - val_loss: 0.9712 - val_accuracy: 0.9004\n",
      "Epoch 49/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.1870e-05 - accuracy: 1.0000 - val_loss: 0.9752 - val_accuracy: 0.8967\n",
      "Epoch 50/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.3941e-05 - accuracy: 1.0000 - val_loss: 0.9788 - val_accuracy: 0.8967\n",
      "Epoch 51/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.0267e-05 - accuracy: 1.0000 - val_loss: 0.9816 - val_accuracy: 0.8967\n",
      "Epoch 52/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.1344e-05 - accuracy: 1.0000 - val_loss: 0.9842 - val_accuracy: 0.8967\n",
      "Epoch 53/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.2606e-05 - accuracy: 1.0000 - val_loss: 0.9904 - val_accuracy: 0.8967\n",
      "Epoch 54/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 9.6431e-06 - accuracy: 1.0000 - val_loss: 0.9949 - val_accuracy: 0.8967\n",
      "Epoch 55/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 6.5508e-06 - accuracy: 1.0000 - val_loss: 0.9970 - val_accuracy: 0.8967\n",
      "Epoch 56/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.4511e-06 - accuracy: 1.0000 - val_loss: 0.9987 - val_accuracy: 0.8967\n",
      "Epoch 57/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 6.7062e-06 - accuracy: 1.0000 - val_loss: 1.0015 - val_accuracy: 0.9004\n",
      "Epoch 58/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 1.1295e-05 - accuracy: 1.0000 - val_loss: 1.0037 - val_accuracy: 0.9004\n",
      "Epoch 59/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 6.7160e-06 - accuracy: 1.0000 - val_loss: 1.0060 - val_accuracy: 0.8967\n",
      "Epoch 60/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 5.4007e-06 - accuracy: 1.0000 - val_loss: 1.0085 - val_accuracy: 0.9004\n",
      "Epoch 61/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 5.9474e-06 - accuracy: 1.0000 - val_loss: 1.0109 - val_accuracy: 0.9004\n",
      "Epoch 62/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.3568e-06 - accuracy: 1.0000 - val_loss: 1.0131 - val_accuracy: 0.9004\n",
      "Epoch 63/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.5216e-06 - accuracy: 1.0000 - val_loss: 1.0158 - val_accuracy: 0.9004\n",
      "Epoch 64/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 5.7991e-06 - accuracy: 1.0000 - val_loss: 1.0181 - val_accuracy: 0.9004\n",
      "Epoch 65/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 6.1754e-06 - accuracy: 1.0000 - val_loss: 1.0200 - val_accuracy: 0.9004\n",
      "Epoch 66/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.3953e-06 - accuracy: 1.0000 - val_loss: 1.0226 - val_accuracy: 0.9004\n",
      "Epoch 67/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 6.1894e-06 - accuracy: 1.0000 - val_loss: 1.0246 - val_accuracy: 0.9004\n",
      "Epoch 68/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.5152e-06 - accuracy: 1.0000 - val_loss: 1.0265 - val_accuracy: 0.9004\n",
      "Epoch 69/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.1932e-06 - accuracy: 1.0000 - val_loss: 1.0277 - val_accuracy: 0.9004\n",
      "Epoch 70/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 5.2539e-06 - accuracy: 1.0000 - val_loss: 1.0306 - val_accuracy: 0.9004\n",
      "Epoch 71/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.3313e-06 - accuracy: 1.0000 - val_loss: 1.0322 - val_accuracy: 0.9004\n",
      "Epoch 72/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.9544e-06 - accuracy: 1.0000 - val_loss: 1.0340 - val_accuracy: 0.9004\n",
      "Epoch 73/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 2.6502e-06 - accuracy: 1.0000 - val_loss: 1.0355 - val_accuracy: 0.9004\n",
      "Epoch 74/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.0915e-06 - accuracy: 1.0000 - val_loss: 1.0369 - val_accuracy: 0.9004\n",
      "Epoch 75/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.7262e-06 - accuracy: 1.0000 - val_loss: 1.0378 - val_accuracy: 0.9004\n",
      "Epoch 76/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 4.2640e-06 - accuracy: 1.0000 - val_loss: 1.0392 - val_accuracy: 0.9004\n",
      "Epoch 77/10000\n",
      "34/34 [==============================] - 1s 40ms/step - loss: 4.2927e-06 - accuracy: 1.0000 - val_loss: 1.0415 - val_accuracy: 0.9004\n",
      "Epoch 78/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.6139e-06 - accuracy: 1.0000 - val_loss: 1.0438 - val_accuracy: 0.9004\n",
      "Epoch 79/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.5615e-06 - accuracy: 1.0000 - val_loss: 1.0450 - val_accuracy: 0.9004\n",
      "Epoch 80/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.9497e-06 - accuracy: 1.0000 - val_loss: 1.0460 - val_accuracy: 0.9004\n",
      "Epoch 81/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.3833e-06 - accuracy: 1.0000 - val_loss: 1.0474 - val_accuracy: 0.9004\n",
      "Epoch 82/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 3.0680e-06 - accuracy: 1.0000 - val_loss: 1.0495 - val_accuracy: 0.9004\n",
      "Epoch 83/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.7538e-06 - accuracy: 1.0000 - val_loss: 1.0509 - val_accuracy: 0.9041\n",
      "Epoch 84/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.3737e-06 - accuracy: 1.0000 - val_loss: 1.0533 - val_accuracy: 0.9041\n",
      "Epoch 85/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.7622e-06 - accuracy: 1.0000 - val_loss: 1.0556 - val_accuracy: 0.9041\n",
      "Epoch 86/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.7490e-06 - accuracy: 1.0000 - val_loss: 1.0585 - val_accuracy: 0.9077\n",
      "Epoch 87/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.1379e-06 - accuracy: 1.0000 - val_loss: 1.0600 - val_accuracy: 0.9077\n",
      "Epoch 88/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 4.2367e-06 - accuracy: 1.0000 - val_loss: 1.0638 - val_accuracy: 0.9077\n",
      "Epoch 89/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.0634e-06 - accuracy: 1.0000 - val_loss: 1.0656 - val_accuracy: 0.9077\n",
      "Epoch 90/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.2599e-06 - accuracy: 1.0000 - val_loss: 1.0666 - val_accuracy: 0.9077\n",
      "Epoch 91/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.4045e-06 - accuracy: 1.0000 - val_loss: 1.0657 - val_accuracy: 0.9041\n",
      "Epoch 92/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.1698e-06 - accuracy: 1.0000 - val_loss: 1.0661 - val_accuracy: 0.9041\n",
      "Epoch 93/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.2065e-06 - accuracy: 1.0000 - val_loss: 1.0686 - val_accuracy: 0.9041\n",
      "Epoch 94/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.6298e-06 - accuracy: 1.0000 - val_loss: 1.0701 - val_accuracy: 0.9041\n",
      "Epoch 95/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 1.5018e-06 - accuracy: 1.0000 - val_loss: 1.0715 - val_accuracy: 0.9041\n",
      "Epoch 96/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.2846e-06 - accuracy: 1.0000 - val_loss: 1.0728 - val_accuracy: 0.9041\n",
      "Epoch 97/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.8922e-06 - accuracy: 1.0000 - val_loss: 1.0752 - val_accuracy: 0.9077\n",
      "Epoch 98/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.2951e-06 - accuracy: 1.0000 - val_loss: 1.0774 - val_accuracy: 0.9077\n",
      "Epoch 99/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.4469e-06 - accuracy: 1.0000 - val_loss: 1.0792 - val_accuracy: 0.9077\n",
      "Epoch 100/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 9.8390e-07 - accuracy: 1.0000 - val_loss: 1.0809 - val_accuracy: 0.9077\n",
      "Epoch 101/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.3583e-06 - accuracy: 1.0000 - val_loss: 1.0820 - val_accuracy: 0.9077\n",
      "Epoch 102/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.7935e-06 - accuracy: 1.0000 - val_loss: 1.0838 - val_accuracy: 0.9077\n",
      "Epoch 103/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.0363e-06 - accuracy: 1.0000 - val_loss: 1.0861 - val_accuracy: 0.9077\n",
      "Epoch 104/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 1.5286e-06 - accuracy: 1.0000 - val_loss: 1.0881 - val_accuracy: 0.9114\n",
      "Epoch 105/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 1.4211e-06 - accuracy: 1.0000 - val_loss: 1.0900 - val_accuracy: 0.9114\n",
      "Epoch 106/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.2741e-06 - accuracy: 1.0000 - val_loss: 1.0918 - val_accuracy: 0.9114\n",
      "Epoch 107/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 1.1016e-06 - accuracy: 1.0000 - val_loss: 1.0936 - val_accuracy: 0.9114\n",
      "Epoch 108/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 1.3973e-06 - accuracy: 1.0000 - val_loss: 1.0949 - val_accuracy: 0.9114\n",
      "Epoch 109/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.2844e-06 - accuracy: 1.0000 - val_loss: 1.0970 - val_accuracy: 0.9114\n",
      "Epoch 110/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.0044e-06 - accuracy: 1.0000 - val_loss: 1.0981 - val_accuracy: 0.9114\n",
      "Epoch 111/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.4849e-06 - accuracy: 1.0000 - val_loss: 1.0995 - val_accuracy: 0.9114\n",
      "Epoch 112/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.1190e-06 - accuracy: 1.0000 - val_loss: 1.1017 - val_accuracy: 0.9114\n",
      "Epoch 113/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 9.6105e-07 - accuracy: 1.0000 - val_loss: 1.1031 - val_accuracy: 0.9114\n",
      "Epoch 114/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 9.6996e-07 - accuracy: 1.0000 - val_loss: 1.1040 - val_accuracy: 0.9114\n",
      "Epoch 115/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 9.6004e-07 - accuracy: 1.0000 - val_loss: 1.1057 - val_accuracy: 0.9114\n",
      "Epoch 116/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 7.1162e-07 - accuracy: 1.0000 - val_loss: 1.1073 - val_accuracy: 0.9114\n",
      "Epoch 117/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.9924e-07 - accuracy: 1.0000 - val_loss: 1.1087 - val_accuracy: 0.9114\n",
      "Epoch 118/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.0416e-06 - accuracy: 1.0000 - val_loss: 1.1103 - val_accuracy: 0.9114\n",
      "Epoch 119/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 6.2400e-07 - accuracy: 1.0000 - val_loss: 1.1112 - val_accuracy: 0.9114\n",
      "Epoch 120/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 9.2742e-07 - accuracy: 1.0000 - val_loss: 1.1128 - val_accuracy: 0.9114\n",
      "Epoch 121/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.8514e-07 - accuracy: 1.0000 - val_loss: 1.1143 - val_accuracy: 0.9114\n",
      "Epoch 122/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.6422e-07 - accuracy: 1.0000 - val_loss: 1.1161 - val_accuracy: 0.9114\n",
      "Epoch 123/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.1792e-07 - accuracy: 1.0000 - val_loss: 1.1188 - val_accuracy: 0.9114\n",
      "Epoch 124/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.5911e-07 - accuracy: 1.0000 - val_loss: 1.1199 - val_accuracy: 0.9114\n",
      "Epoch 125/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.0010e-06 - accuracy: 1.0000 - val_loss: 1.1223 - val_accuracy: 0.9114\n",
      "Epoch 126/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 5.2875e-07 - accuracy: 1.0000 - val_loss: 1.1230 - val_accuracy: 0.9151\n",
      "Epoch 127/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.1055e-07 - accuracy: 1.0000 - val_loss: 1.1251 - val_accuracy: 0.9151\n",
      "Epoch 128/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 5.4913e-07 - accuracy: 1.0000 - val_loss: 1.1262 - val_accuracy: 0.9151\n",
      "Epoch 129/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.1339e-06 - accuracy: 1.0000 - val_loss: 1.1265 - val_accuracy: 0.9114\n",
      "Epoch 130/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 6.0281e-07 - accuracy: 1.0000 - val_loss: 1.1281 - val_accuracy: 0.9114\n",
      "Epoch 131/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 3.7096e-07 - accuracy: 1.0000 - val_loss: 1.1290 - val_accuracy: 0.9151\n",
      "Epoch 132/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 6.1895e-07 - accuracy: 1.0000 - val_loss: 1.1308 - val_accuracy: 0.9151\n",
      "Epoch 133/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 4.3877e-07 - accuracy: 1.0000 - val_loss: 1.1310 - val_accuracy: 0.9151\n",
      "Epoch 134/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 6.4525e-07 - accuracy: 1.0000 - val_loss: 1.1317 - val_accuracy: 0.9151\n",
      "Epoch 135/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 6.8822e-07 - accuracy: 1.0000 - val_loss: 1.1338 - val_accuracy: 0.9151\n",
      "Epoch 136/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.5250e-07 - accuracy: 1.0000 - val_loss: 1.1360 - val_accuracy: 0.9151\n",
      "Epoch 137/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.1909e-07 - accuracy: 1.0000 - val_loss: 1.1384 - val_accuracy: 0.9151\n",
      "Epoch 138/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.1532e-07 - accuracy: 1.0000 - val_loss: 1.1410 - val_accuracy: 0.9151\n",
      "Epoch 139/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 5.9136e-07 - accuracy: 1.0000 - val_loss: 1.1423 - val_accuracy: 0.9151\n",
      "Epoch 140/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 5.0977e-07 - accuracy: 1.0000 - val_loss: 1.1439 - val_accuracy: 0.9151\n",
      "Epoch 141/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 5.0411e-07 - accuracy: 1.0000 - val_loss: 1.1447 - val_accuracy: 0.9151\n",
      "Epoch 142/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 4.2108e-07 - accuracy: 1.0000 - val_loss: 1.1457 - val_accuracy: 0.9151\n",
      "Epoch 143/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.1644e-07 - accuracy: 1.0000 - val_loss: 1.1469 - val_accuracy: 0.9151\n",
      "Epoch 144/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 7.3640e-07 - accuracy: 1.0000 - val_loss: 1.1506 - val_accuracy: 0.9151\n",
      "Epoch 145/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 5.7023e-07 - accuracy: 1.0000 - val_loss: 1.1510 - val_accuracy: 0.9151\n",
      "Epoch 146/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.7206e-07 - accuracy: 1.0000 - val_loss: 1.1521 - val_accuracy: 0.9151\n",
      "Epoch 147/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 7.8859e-07 - accuracy: 1.0000 - val_loss: 1.1562 - val_accuracy: 0.9151\n",
      "Epoch 148/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 5.8626e-07 - accuracy: 1.0000 - val_loss: 1.1596 - val_accuracy: 0.9151\n",
      "Epoch 149/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.2645e-07 - accuracy: 1.0000 - val_loss: 1.1609 - val_accuracy: 0.9151\n",
      "Epoch 150/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.6405e-07 - accuracy: 1.0000 - val_loss: 1.1618 - val_accuracy: 0.9151\n",
      "Epoch 151/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.0283e-07 - accuracy: 1.0000 - val_loss: 1.1625 - val_accuracy: 0.9151\n",
      "Epoch 152/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.2346e-07 - accuracy: 1.0000 - val_loss: 1.1637 - val_accuracy: 0.9151\n",
      "Epoch 153/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 5.3608e-07 - accuracy: 1.0000 - val_loss: 1.1657 - val_accuracy: 0.9151\n",
      "Epoch 154/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.5811e-07 - accuracy: 1.0000 - val_loss: 1.1677 - val_accuracy: 0.9151\n",
      "Epoch 155/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.7153e-07 - accuracy: 1.0000 - val_loss: 1.1690 - val_accuracy: 0.9151\n",
      "Epoch 156/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.0074e-07 - accuracy: 1.0000 - val_loss: 1.1691 - val_accuracy: 0.9151\n",
      "Epoch 157/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.5556e-07 - accuracy: 1.0000 - val_loss: 1.1709 - val_accuracy: 0.9151\n",
      "Epoch 158/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.7464e-07 - accuracy: 1.0000 - val_loss: 1.1725 - val_accuracy: 0.9151\n",
      "Epoch 159/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.0207e-06 - accuracy: 1.0000 - val_loss: 1.1742 - val_accuracy: 0.9151\n",
      "Epoch 160/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 5.2576e-07 - accuracy: 1.0000 - val_loss: 1.1802 - val_accuracy: 0.9151\n",
      "Epoch 161/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.7040e-07 - accuracy: 1.0000 - val_loss: 1.1810 - val_accuracy: 0.9151\n",
      "Epoch 162/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.7690e-07 - accuracy: 1.0000 - val_loss: 1.1808 - val_accuracy: 0.9151\n",
      "Epoch 163/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 8.2233e-07 - accuracy: 1.0000 - val_loss: 1.1814 - val_accuracy: 0.9151\n",
      "Epoch 164/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.9144e-07 - accuracy: 1.0000 - val_loss: 1.1832 - val_accuracy: 0.9151\n",
      "Epoch 165/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.3676e-07 - accuracy: 1.0000 - val_loss: 1.1848 - val_accuracy: 0.9151\n",
      "Epoch 166/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 6.4174e-07 - accuracy: 1.0000 - val_loss: 1.1871 - val_accuracy: 0.9151\n",
      "Epoch 167/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.6440e-07 - accuracy: 1.0000 - val_loss: 1.1885 - val_accuracy: 0.9151\n",
      "Epoch 168/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 2.2637e-07 - accuracy: 1.0000 - val_loss: 1.1912 - val_accuracy: 0.9151\n",
      "Epoch 169/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.4928e-07 - accuracy: 1.0000 - val_loss: 1.1929 - val_accuracy: 0.9151\n",
      "Epoch 170/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.1321e-07 - accuracy: 1.0000 - val_loss: 1.1950 - val_accuracy: 0.9151\n",
      "Epoch 171/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 3.4377e-07 - accuracy: 1.0000 - val_loss: 1.1962 - val_accuracy: 0.9151\n",
      "Epoch 172/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.8697e-07 - accuracy: 1.0000 - val_loss: 1.2004 - val_accuracy: 0.9151\n",
      "Epoch 173/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.8171e-07 - accuracy: 1.0000 - val_loss: 1.2020 - val_accuracy: 0.9151\n",
      "Epoch 174/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 2.6058e-07 - accuracy: 1.0000 - val_loss: 1.2040 - val_accuracy: 0.9151\n",
      "Epoch 175/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.2370e-07 - accuracy: 1.0000 - val_loss: 1.2047 - val_accuracy: 0.9151\n",
      "Epoch 176/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.2177e-07 - accuracy: 1.0000 - val_loss: 1.2056 - val_accuracy: 0.9151\n",
      "Epoch 177/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.2569e-07 - accuracy: 1.0000 - val_loss: 1.2076 - val_accuracy: 0.9151\n",
      "Epoch 178/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.4572e-07 - accuracy: 1.0000 - val_loss: 1.2084 - val_accuracy: 0.9151\n",
      "Epoch 179/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.8672e-07 - accuracy: 1.0000 - val_loss: 1.2098 - val_accuracy: 0.9151\n",
      "Epoch 180/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.9635e-07 - accuracy: 1.0000 - val_loss: 1.2115 - val_accuracy: 0.9151\n",
      "Epoch 181/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.7280e-07 - accuracy: 1.0000 - val_loss: 1.2130 - val_accuracy: 0.9151\n",
      "Epoch 182/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.6326e-07 - accuracy: 1.0000 - val_loss: 1.2139 - val_accuracy: 0.9151\n",
      "Epoch 183/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 1.1361e-07 - accuracy: 1.0000 - val_loss: 1.2151 - val_accuracy: 0.9151\n",
      "Epoch 184/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.5633e-07 - accuracy: 1.0000 - val_loss: 1.2163 - val_accuracy: 0.9151\n",
      "Epoch 185/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.3566e-07 - accuracy: 1.0000 - val_loss: 1.2181 - val_accuracy: 0.9151\n",
      "Epoch 186/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.6496e-07 - accuracy: 1.0000 - val_loss: 1.2190 - val_accuracy: 0.9151\n",
      "Epoch 187/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 2.1996e-07 - accuracy: 1.0000 - val_loss: 1.2220 - val_accuracy: 0.9151\n",
      "Epoch 188/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.2260e-07 - accuracy: 1.0000 - val_loss: 1.2234 - val_accuracy: 0.9151\n",
      "Epoch 189/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.2835e-07 - accuracy: 1.0000 - val_loss: 1.2250 - val_accuracy: 0.9151\n",
      "Epoch 190/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.0844e-07 - accuracy: 1.0000 - val_loss: 1.2254 - val_accuracy: 0.9151\n",
      "Epoch 191/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.6073e-07 - accuracy: 1.0000 - val_loss: 1.2268 - val_accuracy: 0.9151\n",
      "Epoch 192/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.5421e-07 - accuracy: 1.0000 - val_loss: 1.2276 - val_accuracy: 0.9151\n",
      "Epoch 193/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 7.3171e-07 - accuracy: 1.0000 - val_loss: 1.2373 - val_accuracy: 0.9151\n",
      "Epoch 194/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.1502e-06 - accuracy: 1.0000 - val_loss: 1.2267 - val_accuracy: 0.9151\n",
      "Epoch 195/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.0833 - accuracy: 0.9833 - val_loss: 0.5309 - val_accuracy: 0.7786\n",
      "Epoch 196/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.1476 - accuracy: 0.9407 - val_loss: 0.5469 - val_accuracy: 0.8819\n",
      "Epoch 197/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0250 - accuracy: 0.9917 - val_loss: 0.5266 - val_accuracy: 0.8819\n",
      "Epoch 198/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 0.6524 - val_accuracy: 0.8672\n",
      "Epoch 199/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.8021 - val_accuracy: 0.9041\n",
      "Epoch 200/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0104 - accuracy: 0.9954 - val_loss: 0.6629 - val_accuracy: 0.8745\n",
      "Epoch 201/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.7775 - val_accuracy: 0.8930\n",
      "Epoch 202/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.6726 - val_accuracy: 0.8708\n",
      "Epoch 203/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 0.7550 - val_accuracy: 0.9041\n",
      "Epoch 204/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.7708 - val_accuracy: 0.9004\n",
      "Epoch 205/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7890 - val_accuracy: 0.8930\n",
      "Epoch 206/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.8234e-04 - accuracy: 1.0000 - val_loss: 0.8595 - val_accuracy: 0.9004\n",
      "Epoch 207/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 6.6904e-05 - accuracy: 1.0000 - val_loss: 0.8841 - val_accuracy: 0.8967\n",
      "Epoch 208/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 7.2441e-05 - accuracy: 1.0000 - val_loss: 0.8942 - val_accuracy: 0.8967\n",
      "Epoch 209/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.7109e-05 - accuracy: 1.0000 - val_loss: 0.9069 - val_accuracy: 0.9004\n",
      "Epoch 210/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.8214e-05 - accuracy: 1.0000 - val_loss: 0.9130 - val_accuracy: 0.9004\n",
      "Epoch 211/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.8043e-05 - accuracy: 1.0000 - val_loss: 0.9197 - val_accuracy: 0.9004\n",
      "Epoch 212/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.2146e-05 - accuracy: 1.0000 - val_loss: 0.9264 - val_accuracy: 0.9004\n",
      "Epoch 213/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 2.1010e-05 - accuracy: 1.0000 - val_loss: 0.9301 - val_accuracy: 0.9004\n",
      "Epoch 214/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.0071e-05 - accuracy: 1.0000 - val_loss: 0.9338 - val_accuracy: 0.9041\n",
      "Epoch 215/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.7014e-05 - accuracy: 1.0000 - val_loss: 0.9372 - val_accuracy: 0.9041\n",
      "Epoch 216/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.7313e-05 - accuracy: 1.0000 - val_loss: 0.9406 - val_accuracy: 0.9041\n",
      "Epoch 217/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.2546e-05 - accuracy: 1.0000 - val_loss: 0.9442 - val_accuracy: 0.9041\n",
      "Epoch 218/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.6664e-05 - accuracy: 1.0000 - val_loss: 0.9486 - val_accuracy: 0.9041\n",
      "Epoch 219/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.5007e-05 - accuracy: 1.0000 - val_loss: 0.9518 - val_accuracy: 0.9041\n",
      "Epoch 220/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.2149e-05 - accuracy: 1.0000 - val_loss: 0.9541 - val_accuracy: 0.9041\n",
      "Epoch 221/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.5905e-05 - accuracy: 1.0000 - val_loss: 0.9563 - val_accuracy: 0.9041\n",
      "Epoch 222/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.2386e-05 - accuracy: 1.0000 - val_loss: 0.9597 - val_accuracy: 0.9041\n",
      "Epoch 223/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 8.0919e-06 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.9041\n",
      "Epoch 224/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 9.1809e-06 - accuracy: 1.0000 - val_loss: 0.9657 - val_accuracy: 0.9041\n",
      "Epoch 225/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.0800e-05 - accuracy: 1.0000 - val_loss: 0.9679 - val_accuracy: 0.9041\n",
      "Epoch 226/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 9.1187e-06 - accuracy: 1.0000 - val_loss: 0.9699 - val_accuracy: 0.9041\n",
      "Epoch 227/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.2503e-05 - accuracy: 1.0000 - val_loss: 0.9725 - val_accuracy: 0.9041\n",
      "Epoch 228/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 9.9986e-06 - accuracy: 1.0000 - val_loss: 0.9767 - val_accuracy: 0.9041\n",
      "Epoch 229/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 5.8231e-06 - accuracy: 1.0000 - val_loss: 0.9789 - val_accuracy: 0.9041\n",
      "Epoch 230/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.5008e-06 - accuracy: 1.0000 - val_loss: 0.9808 - val_accuracy: 0.9041\n",
      "Epoch 231/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 4.7028e-06 - accuracy: 1.0000 - val_loss: 0.9827 - val_accuracy: 0.9041\n",
      "Epoch 232/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 5.5229e-06 - accuracy: 1.0000 - val_loss: 0.9844 - val_accuracy: 0.9041\n",
      "Epoch 233/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 4.8594e-06 - accuracy: 1.0000 - val_loss: 0.9861 - val_accuracy: 0.9041\n",
      "Epoch 234/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.5054e-06 - accuracy: 1.0000 - val_loss: 0.9877 - val_accuracy: 0.9041\n",
      "Epoch 235/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 7.0686e-06 - accuracy: 1.0000 - val_loss: 0.9892 - val_accuracy: 0.9041\n",
      "Epoch 236/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 5.9880e-06 - accuracy: 1.0000 - val_loss: 0.9912 - val_accuracy: 0.9041\n",
      "Epoch 237/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 5.6303e-06 - accuracy: 1.0000 - val_loss: 0.9932 - val_accuracy: 0.9041\n",
      "Epoch 238/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 5.5007e-06 - accuracy: 1.0000 - val_loss: 0.9951 - val_accuracy: 0.9041\n",
      "Epoch 239/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 6.1079e-06 - accuracy: 1.0000 - val_loss: 0.9974 - val_accuracy: 0.9041\n",
      "Epoch 240/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 5.0807e-06 - accuracy: 1.0000 - val_loss: 0.9995 - val_accuracy: 0.9041\n",
      "Epoch 241/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.6822e-06 - accuracy: 1.0000 - val_loss: 1.0009 - val_accuracy: 0.9041\n",
      "Epoch 242/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.1162e-06 - accuracy: 1.0000 - val_loss: 1.0030 - val_accuracy: 0.9041\n",
      "Epoch 243/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.3482e-06 - accuracy: 1.0000 - val_loss: 1.0048 - val_accuracy: 0.9041\n",
      "Epoch 244/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 4.9500e-06 - accuracy: 1.0000 - val_loss: 1.0070 - val_accuracy: 0.9041\n",
      "Epoch 245/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.5605e-06 - accuracy: 1.0000 - val_loss: 1.0087 - val_accuracy: 0.9041\n",
      "Epoch 246/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 4.0445e-06 - accuracy: 1.0000 - val_loss: 1.0107 - val_accuracy: 0.9041\n",
      "Epoch 247/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.8713e-06 - accuracy: 1.0000 - val_loss: 1.0121 - val_accuracy: 0.9041\n",
      "Epoch 248/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.2494e-06 - accuracy: 1.0000 - val_loss: 1.0139 - val_accuracy: 0.9041\n",
      "Epoch 249/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.8523e-06 - accuracy: 1.0000 - val_loss: 1.0153 - val_accuracy: 0.9041\n",
      "Epoch 250/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.8573e-06 - accuracy: 1.0000 - val_loss: 1.0167 - val_accuracy: 0.9041\n",
      "Epoch 251/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.1713e-06 - accuracy: 1.0000 - val_loss: 1.0185 - val_accuracy: 0.9041\n",
      "Epoch 252/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.4871e-06 - accuracy: 1.0000 - val_loss: 1.0201 - val_accuracy: 0.9041\n",
      "Epoch 253/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 2.9766e-06 - accuracy: 1.0000 - val_loss: 1.0215 - val_accuracy: 0.9041\n",
      "Epoch 254/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.8446e-06 - accuracy: 1.0000 - val_loss: 1.0232 - val_accuracy: 0.9041\n",
      "Epoch 255/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.8934e-06 - accuracy: 1.0000 - val_loss: 1.0250 - val_accuracy: 0.9077\n",
      "Epoch 256/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.9137e-06 - accuracy: 1.0000 - val_loss: 1.0263 - val_accuracy: 0.9041\n",
      "Epoch 257/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.7391e-06 - accuracy: 1.0000 - val_loss: 1.0280 - val_accuracy: 0.9041\n",
      "Epoch 258/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.0074e-06 - accuracy: 1.0000 - val_loss: 1.0295 - val_accuracy: 0.9041\n",
      "Epoch 259/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.6597e-06 - accuracy: 1.0000 - val_loss: 1.0313 - val_accuracy: 0.9077\n",
      "Epoch 260/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.3294e-06 - accuracy: 1.0000 - val_loss: 1.0325 - val_accuracy: 0.9041\n",
      "Epoch 261/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.8225e-06 - accuracy: 1.0000 - val_loss: 1.0344 - val_accuracy: 0.9041\n",
      "Epoch 262/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.4003e-06 - accuracy: 1.0000 - val_loss: 1.0360 - val_accuracy: 0.9077\n",
      "Epoch 263/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.7198e-06 - accuracy: 1.0000 - val_loss: 1.0374 - val_accuracy: 0.9077\n",
      "Epoch 264/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.8073e-06 - accuracy: 1.0000 - val_loss: 1.0392 - val_accuracy: 0.9077\n",
      "Epoch 265/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.2156e-06 - accuracy: 1.0000 - val_loss: 1.0408 - val_accuracy: 0.9077\n",
      "Epoch 266/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.1300e-06 - accuracy: 1.0000 - val_loss: 1.0422 - val_accuracy: 0.9077\n",
      "Epoch 267/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.8747e-06 - accuracy: 1.0000 - val_loss: 1.0441 - val_accuracy: 0.9077\n",
      "Epoch 268/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 1.8867e-06 - accuracy: 1.0000 - val_loss: 1.0460 - val_accuracy: 0.9077\n",
      "Epoch 269/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.8733e-06 - accuracy: 1.0000 - val_loss: 1.0478 - val_accuracy: 0.9077\n",
      "Epoch 270/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.3883e-06 - accuracy: 1.0000 - val_loss: 1.0495 - val_accuracy: 0.9077\n",
      "Epoch 271/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.2566e-06 - accuracy: 1.0000 - val_loss: 1.0506 - val_accuracy: 0.9077\n",
      "Epoch 272/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.3064e-06 - accuracy: 1.0000 - val_loss: 1.0517 - val_accuracy: 0.9077\n",
      "Epoch 273/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.5251e-06 - accuracy: 1.0000 - val_loss: 1.0528 - val_accuracy: 0.9077\n",
      "Epoch 274/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 2.0357e-06 - accuracy: 1.0000 - val_loss: 1.0547 - val_accuracy: 0.9077\n",
      "Epoch 275/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.4912e-06 - accuracy: 1.0000 - val_loss: 1.0550 - val_accuracy: 0.9077\n",
      "Epoch 276/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.4117e-06 - accuracy: 1.0000 - val_loss: 1.0565 - val_accuracy: 0.9077\n",
      "Epoch 277/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 2.5505e-06 - accuracy: 1.0000 - val_loss: 1.0579 - val_accuracy: 0.9077\n",
      "Epoch 278/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.9397e-06 - accuracy: 1.0000 - val_loss: 1.0597 - val_accuracy: 0.9077\n",
      "Epoch 279/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.9471e-06 - accuracy: 1.0000 - val_loss: 1.0615 - val_accuracy: 0.9077\n",
      "Epoch 280/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.4837e-06 - accuracy: 1.0000 - val_loss: 1.0635 - val_accuracy: 0.9077\n",
      "Epoch 281/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.4450e-06 - accuracy: 1.0000 - val_loss: 1.0651 - val_accuracy: 0.9077\n",
      "Epoch 282/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 1.0768e-06 - accuracy: 1.0000 - val_loss: 1.0663 - val_accuracy: 0.9077\n",
      "Epoch 283/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.3565e-06 - accuracy: 1.0000 - val_loss: 1.0681 - val_accuracy: 0.9077\n",
      "Epoch 284/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.4077e-06 - accuracy: 1.0000 - val_loss: 1.0700 - val_accuracy: 0.9077\n",
      "Epoch 285/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.3405e-06 - accuracy: 1.0000 - val_loss: 1.0712 - val_accuracy: 0.9077\n",
      "Epoch 286/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.8341e-06 - accuracy: 1.0000 - val_loss: 1.0726 - val_accuracy: 0.9077\n",
      "Epoch 287/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.0230e-06 - accuracy: 1.0000 - val_loss: 1.0741 - val_accuracy: 0.9077\n",
      "Epoch 288/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.2905e-06 - accuracy: 1.0000 - val_loss: 1.0757 - val_accuracy: 0.9077\n",
      "Epoch 289/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 9.1686e-07 - accuracy: 1.0000 - val_loss: 1.0768 - val_accuracy: 0.9077\n",
      "Epoch 290/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.9261e-07 - accuracy: 1.0000 - val_loss: 1.0783 - val_accuracy: 0.9077\n",
      "Epoch 291/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.1772e-06 - accuracy: 1.0000 - val_loss: 1.0796 - val_accuracy: 0.9077\n",
      "Epoch 292/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.0348e-06 - accuracy: 1.0000 - val_loss: 1.0813 - val_accuracy: 0.9077\n",
      "Epoch 293/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 9.4022e-07 - accuracy: 1.0000 - val_loss: 1.0826 - val_accuracy: 0.9077\n",
      "Epoch 294/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.0434e-06 - accuracy: 1.0000 - val_loss: 1.0842 - val_accuracy: 0.9077\n",
      "Epoch 295/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 9.9481e-07 - accuracy: 1.0000 - val_loss: 1.0853 - val_accuracy: 0.9077\n",
      "Epoch 296/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 7.8985e-07 - accuracy: 1.0000 - val_loss: 1.0869 - val_accuracy: 0.9077\n",
      "Epoch 297/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 9.2215e-07 - accuracy: 1.0000 - val_loss: 1.0883 - val_accuracy: 0.9077\n",
      "Epoch 298/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 9.3532e-07 - accuracy: 1.0000 - val_loss: 1.0895 - val_accuracy: 0.9077\n",
      "Epoch 299/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 8.3679e-07 - accuracy: 1.0000 - val_loss: 1.0909 - val_accuracy: 0.9077\n",
      "Epoch 300/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 2.8404e-06 - accuracy: 1.0000 - val_loss: 1.0892 - val_accuracy: 0.9077\n",
      "Epoch 301/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.2859e-06 - accuracy: 1.0000 - val_loss: 1.0907 - val_accuracy: 0.9077\n",
      "Epoch 302/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.1108e-06 - accuracy: 1.0000 - val_loss: 1.0925 - val_accuracy: 0.9077\n",
      "Epoch 303/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 7.0352e-07 - accuracy: 1.0000 - val_loss: 1.0942 - val_accuracy: 0.9077\n",
      "Epoch 304/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.2081e-07 - accuracy: 1.0000 - val_loss: 1.0961 - val_accuracy: 0.9077\n",
      "Epoch 305/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 7.7412e-07 - accuracy: 1.0000 - val_loss: 1.0979 - val_accuracy: 0.9077\n",
      "Epoch 306/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.0659e-06 - accuracy: 1.0000 - val_loss: 1.0995 - val_accuracy: 0.9077\n",
      "Epoch 307/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 6.0338e-07 - accuracy: 1.0000 - val_loss: 1.1006 - val_accuracy: 0.9077\n",
      "Epoch 308/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 9.4656e-07 - accuracy: 1.0000 - val_loss: 1.1025 - val_accuracy: 0.9077\n",
      "Epoch 309/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.0160e-07 - accuracy: 1.0000 - val_loss: 1.1041 - val_accuracy: 0.9077\n",
      "Epoch 310/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 7.2251e-07 - accuracy: 1.0000 - val_loss: 1.1057 - val_accuracy: 0.9077\n",
      "Epoch 311/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 7.6613e-07 - accuracy: 1.0000 - val_loss: 1.1073 - val_accuracy: 0.9077\n",
      "Epoch 312/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 6.0919e-07 - accuracy: 1.0000 - val_loss: 1.1087 - val_accuracy: 0.9077\n",
      "Epoch 313/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.9770e-07 - accuracy: 1.0000 - val_loss: 1.1101 - val_accuracy: 0.9077\n",
      "Epoch 314/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 5.4209e-07 - accuracy: 1.0000 - val_loss: 1.1111 - val_accuracy: 0.9077\n",
      "Epoch 315/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.1155e-06 - accuracy: 1.0000 - val_loss: 1.1118 - val_accuracy: 0.9077\n",
      "Epoch 316/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 7.2057e-07 - accuracy: 1.0000 - val_loss: 1.1132 - val_accuracy: 0.9077\n",
      "Epoch 317/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 5.8146e-07 - accuracy: 1.0000 - val_loss: 1.1148 - val_accuracy: 0.9077\n",
      "Epoch 318/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 5.8620e-07 - accuracy: 1.0000 - val_loss: 1.1168 - val_accuracy: 0.9077\n",
      "Epoch 319/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 5.1820e-07 - accuracy: 1.0000 - val_loss: 1.1179 - val_accuracy: 0.9077\n",
      "Epoch 320/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.1556e-07 - accuracy: 1.0000 - val_loss: 1.1193 - val_accuracy: 0.9077\n",
      "Epoch 321/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 5.0674e-07 - accuracy: 1.0000 - val_loss: 1.1212 - val_accuracy: 0.9077\n",
      "Epoch 322/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.6149e-07 - accuracy: 1.0000 - val_loss: 1.1225 - val_accuracy: 0.9077\n",
      "Epoch 323/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 5.2111e-07 - accuracy: 1.0000 - val_loss: 1.1241 - val_accuracy: 0.9077\n",
      "Epoch 324/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 4.8435e-07 - accuracy: 1.0000 - val_loss: 1.1258 - val_accuracy: 0.9077\n",
      "Epoch 325/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.9525e-07 - accuracy: 1.0000 - val_loss: 1.1272 - val_accuracy: 0.9077\n",
      "Epoch 326/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 5.0060e-07 - accuracy: 1.0000 - val_loss: 1.1291 - val_accuracy: 0.9077\n",
      "Epoch 327/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.5146e-06 - accuracy: 1.0000 - val_loss: 1.1293 - val_accuracy: 0.9077\n",
      "Epoch 328/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 4.7759e-07 - accuracy: 1.0000 - val_loss: 1.1298 - val_accuracy: 0.9077\n",
      "Epoch 329/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.5898e-07 - accuracy: 1.0000 - val_loss: 1.1316 - val_accuracy: 0.9077\n",
      "Epoch 330/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 3.6847e-07 - accuracy: 1.0000 - val_loss: 1.1335 - val_accuracy: 0.9077\n",
      "Epoch 331/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 4.0372e-07 - accuracy: 1.0000 - val_loss: 1.1346 - val_accuracy: 0.9077\n",
      "Epoch 332/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.1871e-07 - accuracy: 1.0000 - val_loss: 1.1368 - val_accuracy: 0.9077\n",
      "Epoch 333/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 7.2504e-07 - accuracy: 1.0000 - val_loss: 1.1391 - val_accuracy: 0.9077\n",
      "Epoch 334/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.9272e-07 - accuracy: 1.0000 - val_loss: 1.1404 - val_accuracy: 0.9077\n",
      "Epoch 335/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 4.7683e-07 - accuracy: 1.0000 - val_loss: 1.1421 - val_accuracy: 0.9077\n",
      "Epoch 336/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 5.5318e-07 - accuracy: 1.0000 - val_loss: 1.1436 - val_accuracy: 0.9077\n",
      "Epoch 337/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.9772e-07 - accuracy: 1.0000 - val_loss: 1.1452 - val_accuracy: 0.9077\n",
      "Epoch 338/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.4661e-07 - accuracy: 1.0000 - val_loss: 1.1474 - val_accuracy: 0.9077\n",
      "Epoch 339/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.3651e-07 - accuracy: 1.0000 - val_loss: 1.1485 - val_accuracy: 0.9077\n",
      "Epoch 340/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.7013e-07 - accuracy: 1.0000 - val_loss: 1.1502 - val_accuracy: 0.9077\n",
      "Epoch 341/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 3.6920e-07 - accuracy: 1.0000 - val_loss: 1.1514 - val_accuracy: 0.9077\n",
      "Epoch 342/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 6.5981e-07 - accuracy: 1.0000 - val_loss: 1.1521 - val_accuracy: 0.9077\n",
      "Epoch 343/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 3.5795e-07 - accuracy: 1.0000 - val_loss: 1.1531 - val_accuracy: 0.9077\n",
      "Epoch 344/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.9659e-07 - accuracy: 1.0000 - val_loss: 1.1546 - val_accuracy: 0.9077\n",
      "Epoch 345/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.1900e-07 - accuracy: 1.0000 - val_loss: 1.1562 - val_accuracy: 0.9077\n",
      "Epoch 346/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 2.6450e-07 - accuracy: 1.0000 - val_loss: 1.1572 - val_accuracy: 0.9077\n",
      "Epoch 347/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.7085e-07 - accuracy: 1.0000 - val_loss: 1.1585 - val_accuracy: 0.9077\n",
      "Epoch 348/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.3578e-07 - accuracy: 1.0000 - val_loss: 1.1599 - val_accuracy: 0.9077\n",
      "Epoch 349/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.6482e-07 - accuracy: 1.0000 - val_loss: 1.1614 - val_accuracy: 0.9077\n",
      "Epoch 350/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.1534e-07 - accuracy: 1.0000 - val_loss: 1.1628 - val_accuracy: 0.9077\n",
      "Epoch 351/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.8601e-07 - accuracy: 1.0000 - val_loss: 1.1640 - val_accuracy: 0.9077\n",
      "Epoch 352/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.9066e-07 - accuracy: 1.0000 - val_loss: 1.1653 - val_accuracy: 0.9004\n",
      "Epoch 353/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.7515e-07 - accuracy: 1.0000 - val_loss: 1.1663 - val_accuracy: 0.9004\n",
      "Epoch 354/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.1736e-07 - accuracy: 1.0000 - val_loss: 1.1676 - val_accuracy: 0.9004\n",
      "Epoch 355/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.7461e-07 - accuracy: 1.0000 - val_loss: 1.1691 - val_accuracy: 0.9004\n",
      "Epoch 356/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.8923e-07 - accuracy: 1.0000 - val_loss: 1.1702 - val_accuracy: 0.9004\n",
      "Epoch 357/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.0554e-07 - accuracy: 1.0000 - val_loss: 1.1720 - val_accuracy: 0.9004\n",
      "Epoch 358/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 2.8548e-07 - accuracy: 1.0000 - val_loss: 1.1732 - val_accuracy: 0.9004\n",
      "Epoch 359/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.5953e-07 - accuracy: 1.0000 - val_loss: 1.1743 - val_accuracy: 0.9004\n",
      "Epoch 360/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.4450e-07 - accuracy: 1.0000 - val_loss: 1.1757 - val_accuracy: 0.9004\n",
      "Epoch 361/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.3827e-07 - accuracy: 1.0000 - val_loss: 1.1769 - val_accuracy: 0.9004\n",
      "Epoch 362/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.4683e-07 - accuracy: 1.0000 - val_loss: 1.1781 - val_accuracy: 0.9004\n",
      "Epoch 363/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.7113e-07 - accuracy: 1.0000 - val_loss: 1.1793 - val_accuracy: 0.9004\n",
      "Epoch 364/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 2.6723e-07 - accuracy: 1.0000 - val_loss: 1.1805 - val_accuracy: 0.9004\n",
      "Epoch 365/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.4480e-07 - accuracy: 1.0000 - val_loss: 1.1818 - val_accuracy: 0.9004\n",
      "Epoch 366/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.2847e-07 - accuracy: 1.0000 - val_loss: 1.1830 - val_accuracy: 0.9004\n",
      "Epoch 367/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.7851e-07 - accuracy: 1.0000 - val_loss: 1.1839 - val_accuracy: 0.9004\n",
      "Epoch 368/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.9614e-07 - accuracy: 1.0000 - val_loss: 1.1851 - val_accuracy: 0.9004\n",
      "Epoch 369/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.4390e-07 - accuracy: 1.0000 - val_loss: 1.1862 - val_accuracy: 0.9004\n",
      "Epoch 370/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.8670e-07 - accuracy: 1.0000 - val_loss: 1.1874 - val_accuracy: 0.9004\n",
      "Epoch 371/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.5502e-07 - accuracy: 1.0000 - val_loss: 1.1886 - val_accuracy: 0.9004\n",
      "Epoch 372/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.0439e-07 - accuracy: 1.0000 - val_loss: 1.1897 - val_accuracy: 0.9004\n",
      "Epoch 373/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.0906e-07 - accuracy: 1.0000 - val_loss: 1.1914 - val_accuracy: 0.9004\n",
      "Epoch 374/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.2725e-07 - accuracy: 1.0000 - val_loss: 1.1924 - val_accuracy: 0.9004\n",
      "Epoch 375/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.8718e-07 - accuracy: 1.0000 - val_loss: 1.1936 - val_accuracy: 0.9004\n",
      "Epoch 376/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.9678e-07 - accuracy: 1.0000 - val_loss: 1.1948 - val_accuracy: 0.9004\n",
      "Epoch 377/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.4725e-07 - accuracy: 1.0000 - val_loss: 1.1958 - val_accuracy: 0.9004\n",
      "Epoch 378/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.7483e-07 - accuracy: 1.0000 - val_loss: 1.1968 - val_accuracy: 0.9004\n",
      "Epoch 379/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.8884e-07 - accuracy: 1.0000 - val_loss: 1.1981 - val_accuracy: 0.9004\n",
      "Epoch 380/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.6523e-07 - accuracy: 1.0000 - val_loss: 1.1994 - val_accuracy: 0.9004\n",
      "Epoch 381/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.9144e-07 - accuracy: 1.0000 - val_loss: 1.2010 - val_accuracy: 0.9004\n",
      "Epoch 382/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.7217e-07 - accuracy: 1.0000 - val_loss: 1.2019 - val_accuracy: 0.9004\n",
      "Epoch 383/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.5726e-07 - accuracy: 1.0000 - val_loss: 1.2038 - val_accuracy: 0.9004\n",
      "Epoch 384/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.8710e-07 - accuracy: 1.0000 - val_loss: 1.2050 - val_accuracy: 0.9004\n",
      "Epoch 385/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.4946e-07 - accuracy: 1.0000 - val_loss: 1.2066 - val_accuracy: 0.9004\n",
      "Epoch 386/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.4226e-07 - accuracy: 1.0000 - val_loss: 1.2076 - val_accuracy: 0.9004\n",
      "Epoch 387/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.1558e-07 - accuracy: 1.0000 - val_loss: 1.2088 - val_accuracy: 0.9004\n",
      "Epoch 388/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.2097e-07 - accuracy: 1.0000 - val_loss: 1.2100 - val_accuracy: 0.9004\n",
      "Epoch 389/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.3421e-07 - accuracy: 1.0000 - val_loss: 1.2114 - val_accuracy: 0.9004\n",
      "Epoch 390/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.3781e-07 - accuracy: 1.0000 - val_loss: 1.2130 - val_accuracy: 0.9004\n",
      "Epoch 391/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 9.9228e-08 - accuracy: 1.0000 - val_loss: 1.2141 - val_accuracy: 0.9004\n",
      "Epoch 392/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.1365e-07 - accuracy: 1.0000 - val_loss: 1.2151 - val_accuracy: 0.9004\n",
      "Epoch 393/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.2924e-07 - accuracy: 1.0000 - val_loss: 1.2162 - val_accuracy: 0.9004\n",
      "Epoch 394/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.7229e-07 - accuracy: 1.0000 - val_loss: 1.2179 - val_accuracy: 0.9004\n",
      "Epoch 395/10000\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 1.4134e-07 - accuracy: 1.0000 - val_loss: 1.2194 - val_accuracy: 0.9004\n",
      "Epoch 396/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.1954e-07 - accuracy: 1.0000 - val_loss: 1.2204 - val_accuracy: 0.9004\n",
      "Epoch 397/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.1511e-07 - accuracy: 1.0000 - val_loss: 1.2217 - val_accuracy: 0.9004\n",
      "Epoch 398/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.3876e-07 - accuracy: 1.0000 - val_loss: 1.2231 - val_accuracy: 0.9004\n",
      "Epoch 399/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.4802e-07 - accuracy: 1.0000 - val_loss: 1.2246 - val_accuracy: 0.9004\n",
      "Epoch 400/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 8.3301e-08 - accuracy: 1.0000 - val_loss: 1.2259 - val_accuracy: 0.9004\n",
      "Epoch 401/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.2857e-07 - accuracy: 1.0000 - val_loss: 1.2270 - val_accuracy: 0.9004\n",
      "Epoch 402/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.0153e-07 - accuracy: 1.0000 - val_loss: 1.2279 - val_accuracy: 0.9004\n",
      "Epoch 403/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.0594e-07 - accuracy: 1.0000 - val_loss: 1.2289 - val_accuracy: 0.9004\n",
      "Epoch 404/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.0782e-07 - accuracy: 1.0000 - val_loss: 1.2302 - val_accuracy: 0.9004\n",
      "Epoch 405/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.0904e-07 - accuracy: 1.0000 - val_loss: 1.2311 - val_accuracy: 0.9004\n",
      "Epoch 406/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.2038e-07 - accuracy: 1.0000 - val_loss: 1.2324 - val_accuracy: 0.9004\n",
      "Epoch 407/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.3748e-08 - accuracy: 1.0000 - val_loss: 1.2341 - val_accuracy: 0.9004\n",
      "Epoch 408/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 7.5348e-08 - accuracy: 1.0000 - val_loss: 1.2366 - val_accuracy: 0.9004\n",
      "Epoch 409/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.6676e-08 - accuracy: 1.0000 - val_loss: 1.2377 - val_accuracy: 0.9004\n",
      "Epoch 410/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.0375e-07 - accuracy: 1.0000 - val_loss: 1.2389 - val_accuracy: 0.9004\n",
      "Epoch 411/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.0531e-08 - accuracy: 1.0000 - val_loss: 1.2399 - val_accuracy: 0.9004\n",
      "Epoch 412/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 8.2434e-08 - accuracy: 1.0000 - val_loss: 1.2413 - val_accuracy: 0.9004\n",
      "Epoch 413/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.7111e-08 - accuracy: 1.0000 - val_loss: 1.2422 - val_accuracy: 0.9004\n",
      "Epoch 414/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 8.6437e-08 - accuracy: 1.0000 - val_loss: 1.2433 - val_accuracy: 0.9004\n",
      "Epoch 415/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.5310e-08 - accuracy: 1.0000 - val_loss: 1.2445 - val_accuracy: 0.9004\n",
      "Epoch 416/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 6.1833e-08 - accuracy: 1.0000 - val_loss: 1.2455 - val_accuracy: 0.9004\n",
      "Epoch 417/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 7.7892e-08 - accuracy: 1.0000 - val_loss: 1.2468 - val_accuracy: 0.9004\n",
      "Epoch 418/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.8785e-08 - accuracy: 1.0000 - val_loss: 1.2478 - val_accuracy: 0.9004\n",
      "Epoch 419/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.8787e-07 - accuracy: 1.0000 - val_loss: 1.2497 - val_accuracy: 0.9004\n",
      "Epoch 420/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.2085e-07 - accuracy: 1.0000 - val_loss: 1.2522 - val_accuracy: 0.9004\n",
      "Epoch 421/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 6.3125e-08 - accuracy: 1.0000 - val_loss: 1.2536 - val_accuracy: 0.9004\n",
      "Epoch 422/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.0203e-07 - accuracy: 1.0000 - val_loss: 1.2551 - val_accuracy: 0.9004\n",
      "Epoch 423/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 9.9259e-08 - accuracy: 1.0000 - val_loss: 1.2566 - val_accuracy: 0.9004\n",
      "Epoch 424/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 7.5574e-08 - accuracy: 1.0000 - val_loss: 1.2579 - val_accuracy: 0.9004\n",
      "Epoch 425/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.1155e-07 - accuracy: 1.0000 - val_loss: 1.2591 - val_accuracy: 0.9004\n",
      "Epoch 426/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.7157e-08 - accuracy: 1.0000 - val_loss: 1.2605 - val_accuracy: 0.9004\n",
      "Epoch 427/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 7.0603e-08 - accuracy: 1.0000 - val_loss: 1.2620 - val_accuracy: 0.9004\n",
      "Epoch 428/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.6419e-08 - accuracy: 1.0000 - val_loss: 1.2629 - val_accuracy: 0.9004\n",
      "Epoch 429/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 6.3993e-08 - accuracy: 1.0000 - val_loss: 1.2640 - val_accuracy: 0.9004\n",
      "Epoch 430/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.6963e-08 - accuracy: 1.0000 - val_loss: 1.2651 - val_accuracy: 0.9004\n",
      "Epoch 431/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 6.1606e-08 - accuracy: 1.0000 - val_loss: 1.2666 - val_accuracy: 0.9004\n",
      "Epoch 432/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.3152e-08 - accuracy: 1.0000 - val_loss: 1.2681 - val_accuracy: 0.9004\n",
      "Epoch 433/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 5.1617e-08 - accuracy: 1.0000 - val_loss: 1.2692 - val_accuracy: 0.9004\n",
      "Epoch 434/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 6.8793e-08 - accuracy: 1.0000 - val_loss: 1.2704 - val_accuracy: 0.9004\n",
      "Epoch 435/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 7.6483e-08 - accuracy: 1.0000 - val_loss: 1.2718 - val_accuracy: 0.9004\n",
      "Epoch 436/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.7847e-08 - accuracy: 1.0000 - val_loss: 1.2730 - val_accuracy: 0.9004\n",
      "Epoch 437/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 4.2147e-08 - accuracy: 1.0000 - val_loss: 1.2739 - val_accuracy: 0.9004\n",
      "Epoch 438/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.5281e-08 - accuracy: 1.0000 - val_loss: 1.2750 - val_accuracy: 0.9004\n",
      "Epoch 439/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 5.0447e-08 - accuracy: 1.0000 - val_loss: 1.2761 - val_accuracy: 0.9004\n",
      "Epoch 440/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 5.8002e-08 - accuracy: 1.0000 - val_loss: 1.2772 - val_accuracy: 0.9004\n",
      "Epoch 441/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 4.7953e-07 - accuracy: 1.0000 - val_loss: 1.2817 - val_accuracy: 0.9004\n",
      "Epoch 442/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 4.8905e-08 - accuracy: 1.0000 - val_loss: 1.2839 - val_accuracy: 0.9004\n",
      "Epoch 443/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.7742e-08 - accuracy: 1.0000 - val_loss: 1.2846 - val_accuracy: 0.9004\n",
      "Epoch 444/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.8165e-08 - accuracy: 1.0000 - val_loss: 1.2855 - val_accuracy: 0.9004\n",
      "Epoch 445/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.5566e-07 - accuracy: 1.0000 - val_loss: 1.2873 - val_accuracy: 0.9004\n",
      "Epoch 446/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 4.5562e-08 - accuracy: 1.0000 - val_loss: 1.2887 - val_accuracy: 0.9004\n",
      "Epoch 447/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.3356e-08 - accuracy: 1.0000 - val_loss: 1.2899 - val_accuracy: 0.9004\n",
      "Epoch 448/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 6.0310e-08 - accuracy: 1.0000 - val_loss: 1.2914 - val_accuracy: 0.9004\n",
      "Epoch 449/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 5.1621e-08 - accuracy: 1.0000 - val_loss: 1.2929 - val_accuracy: 0.9004\n",
      "Epoch 450/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 5.5831e-08 - accuracy: 1.0000 - val_loss: 1.2936 - val_accuracy: 0.9004\n",
      "Epoch 451/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 5.2219e-08 - accuracy: 1.0000 - val_loss: 1.2946 - val_accuracy: 0.9004\n",
      "Epoch 452/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.7505e-08 - accuracy: 1.0000 - val_loss: 1.2959 - val_accuracy: 0.9004\n",
      "Epoch 453/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.6386e-08 - accuracy: 1.0000 - val_loss: 1.2969 - val_accuracy: 0.9004\n",
      "Epoch 454/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 6.4154e-08 - accuracy: 1.0000 - val_loss: 1.2985 - val_accuracy: 0.9004\n",
      "Epoch 455/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.3915e-08 - accuracy: 1.0000 - val_loss: 1.2999 - val_accuracy: 0.9004\n",
      "Epoch 456/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.1562e-08 - accuracy: 1.0000 - val_loss: 1.3010 - val_accuracy: 0.9004\n",
      "Epoch 457/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.2831e-08 - accuracy: 1.0000 - val_loss: 1.3020 - val_accuracy: 0.9004\n",
      "Epoch 458/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 6.9455e-08 - accuracy: 1.0000 - val_loss: 1.3034 - val_accuracy: 0.9004\n",
      "Epoch 459/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.6819e-08 - accuracy: 1.0000 - val_loss: 1.3047 - val_accuracy: 0.9004\n",
      "Epoch 460/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.4036e-08 - accuracy: 1.0000 - val_loss: 1.3058 - val_accuracy: 0.9004\n",
      "Epoch 461/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 5.3239e-08 - accuracy: 1.0000 - val_loss: 1.3074 - val_accuracy: 0.9004\n",
      "Epoch 462/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 2.6434e-08 - accuracy: 1.0000 - val_loss: 1.3083 - val_accuracy: 0.9004\n",
      "Epoch 463/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.1664e-08 - accuracy: 1.0000 - val_loss: 1.3094 - val_accuracy: 0.9004\n",
      "Epoch 464/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.3985e-08 - accuracy: 1.0000 - val_loss: 1.3107 - val_accuracy: 0.9004\n",
      "Epoch 465/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.0119e-08 - accuracy: 1.0000 - val_loss: 1.3118 - val_accuracy: 0.9004\n",
      "Epoch 466/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.3000e-08 - accuracy: 1.0000 - val_loss: 1.3128 - val_accuracy: 0.9004\n",
      "Epoch 467/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.6942e-08 - accuracy: 1.0000 - val_loss: 1.3138 - val_accuracy: 0.9004\n",
      "Epoch 468/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.0793e-08 - accuracy: 1.0000 - val_loss: 1.3149 - val_accuracy: 0.9004\n",
      "Epoch 469/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.2334e-08 - accuracy: 1.0000 - val_loss: 1.3163 - val_accuracy: 0.9004\n",
      "Epoch 470/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.8148e-08 - accuracy: 1.0000 - val_loss: 1.3174 - val_accuracy: 0.9004\n",
      "Epoch 471/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.0857e-08 - accuracy: 1.0000 - val_loss: 1.3186 - val_accuracy: 0.9004\n",
      "Epoch 472/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.2418e-08 - accuracy: 1.0000 - val_loss: 1.3207 - val_accuracy: 0.9004\n",
      "Epoch 473/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.5122e-08 - accuracy: 1.0000 - val_loss: 1.3224 - val_accuracy: 0.9004\n",
      "Epoch 474/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.4318e-08 - accuracy: 1.0000 - val_loss: 1.3234 - val_accuracy: 0.9004\n",
      "Epoch 475/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.0402e-08 - accuracy: 1.0000 - val_loss: 1.3238 - val_accuracy: 0.9004\n",
      "Epoch 476/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 3.0928e-08 - accuracy: 1.0000 - val_loss: 1.3255 - val_accuracy: 0.9004\n",
      "Epoch 477/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.9169e-08 - accuracy: 1.0000 - val_loss: 1.3264 - val_accuracy: 0.9004\n",
      "Epoch 478/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.8598e-08 - accuracy: 1.0000 - val_loss: 1.3274 - val_accuracy: 0.9004\n",
      "Epoch 479/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 4.0119e-08 - accuracy: 1.0000 - val_loss: 1.3285 - val_accuracy: 0.9004\n",
      "Epoch 480/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.6903e-08 - accuracy: 1.0000 - val_loss: 1.3299 - val_accuracy: 0.9004\n",
      "Epoch 481/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.9189e-08 - accuracy: 1.0000 - val_loss: 1.3307 - val_accuracy: 0.9004\n",
      "Epoch 482/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.8646e-08 - accuracy: 1.0000 - val_loss: 1.3330 - val_accuracy: 0.9004\n",
      "Epoch 483/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 2.7050e-08 - accuracy: 1.0000 - val_loss: 1.3343 - val_accuracy: 0.9004\n",
      "Epoch 484/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.0197e-08 - accuracy: 1.0000 - val_loss: 1.3351 - val_accuracy: 0.9004\n",
      "Epoch 485/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 2.6826e-08 - accuracy: 1.0000 - val_loss: 1.3364 - val_accuracy: 0.9004\n",
      "Epoch 486/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.8449e-08 - accuracy: 1.0000 - val_loss: 1.3374 - val_accuracy: 0.9004\n",
      "Epoch 487/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.9999e-08 - accuracy: 1.0000 - val_loss: 1.3381 - val_accuracy: 0.9004\n",
      "Epoch 488/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 9.3571e-08 - accuracy: 1.0000 - val_loss: 1.3348 - val_accuracy: 0.9041\n",
      "Epoch 489/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 4.4295e-07 - accuracy: 1.0000 - val_loss: 1.3483 - val_accuracy: 0.8893\n",
      "Epoch 490/10000\n",
      "34/34 [==============================] - 1s 42ms/step - loss: 1.4885e-06 - accuracy: 1.0000 - val_loss: 1.3588 - val_accuracy: 0.9041\n",
      "Epoch 491/10000\n",
      "34/34 [==============================] - 1s 40ms/step - loss: 0.0705 - accuracy: 0.9806 - val_loss: 0.4601 - val_accuracy: 0.9114\n",
      "Epoch 492/10000\n",
      "34/34 [==============================] - 1s 43ms/step - loss: 0.0366 - accuracy: 0.9880 - val_loss: 0.4161 - val_accuracy: 0.8672\n",
      "Epoch 493/10000\n",
      "34/34 [==============================] - 1s 40ms/step - loss: 0.0319 - accuracy: 0.9898 - val_loss: 0.7481 - val_accuracy: 0.8893\n",
      "Epoch 494/10000\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 0.0154 - accuracy: 0.9944 - val_loss: 0.9193 - val_accuracy: 0.8893\n",
      "Epoch 495/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 1.1609 - val_accuracy: 0.8967\n",
      "Epoch 496/10000\n",
      "34/34 [==============================] - 1s 40ms/step - loss: 4.3047e-04 - accuracy: 1.0000 - val_loss: 1.2995 - val_accuracy: 0.8930\n",
      "Epoch 497/10000\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 1.2489 - val_accuracy: 0.9041\n",
      "Epoch 498/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.0027 - accuracy: 0.9981 - val_loss: 1.0767 - val_accuracy: 0.8893\n",
      "Epoch 499/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.9503 - val_accuracy: 0.8782\n",
      "Epoch 500/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.0644 - val_accuracy: 0.8967\n",
      "Epoch 501/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0017 - accuracy: 0.9991 - val_loss: 1.1175 - val_accuracy: 0.9077\n",
      "Epoch 502/10000\n",
      "34/34 [==============================] - 1s 43ms/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 0.8809 - val_accuracy: 0.8635\n",
      "Epoch 503/10000\n",
      "34/34 [==============================] - 2s 47ms/step - loss: 0.0045 - accuracy: 0.9963 - val_loss: 1.0123 - val_accuracy: 0.8819\n",
      "Epoch 504/10000\n",
      "34/34 [==============================] - 1s 40ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1687 - val_accuracy: 0.8819\n",
      "Epoch 505/10000\n",
      "34/34 [==============================] - 1s 40ms/step - loss: 3.5114e-04 - accuracy: 1.0000 - val_loss: 1.2237 - val_accuracy: 0.8856\n",
      "Epoch 506/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 9.4602e-05 - accuracy: 1.0000 - val_loss: 1.2691 - val_accuracy: 0.8856\n",
      "Epoch 507/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 2.2509e-05 - accuracy: 1.0000 - val_loss: 1.2853 - val_accuracy: 0.8893\n",
      "Epoch 508/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.4704e-05 - accuracy: 1.0000 - val_loss: 1.2921 - val_accuracy: 0.8893\n",
      "Epoch 509/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 1.0500e-05 - accuracy: 1.0000 - val_loss: 1.2958 - val_accuracy: 0.8893\n",
      "Epoch 510/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.0525e-05 - accuracy: 1.0000 - val_loss: 1.3022 - val_accuracy: 0.8930\n",
      "Epoch 511/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.6357e-05 - accuracy: 1.0000 - val_loss: 1.3060 - val_accuracy: 0.8930\n",
      "Epoch 512/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 7.0878e-06 - accuracy: 1.0000 - val_loss: 1.3134 - val_accuracy: 0.8930\n",
      "Epoch 513/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.7275e-06 - accuracy: 1.0000 - val_loss: 1.3162 - val_accuracy: 0.8930\n",
      "Epoch 514/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 5.6402e-06 - accuracy: 1.0000 - val_loss: 1.3196 - val_accuracy: 0.8930\n",
      "Epoch 515/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 7.1819e-06 - accuracy: 1.0000 - val_loss: 1.3244 - val_accuracy: 0.8930\n",
      "Epoch 516/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.9449e-06 - accuracy: 1.0000 - val_loss: 1.3270 - val_accuracy: 0.8930\n",
      "Epoch 517/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 2.5954e-06 - accuracy: 1.0000 - val_loss: 1.3289 - val_accuracy: 0.8930\n",
      "Epoch 518/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 6.2453e-06 - accuracy: 1.0000 - val_loss: 1.3327 - val_accuracy: 0.8930\n",
      "Epoch 519/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.4031e-06 - accuracy: 1.0000 - val_loss: 1.3353 - val_accuracy: 0.8930\n",
      "Epoch 520/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 4.3293e-06 - accuracy: 1.0000 - val_loss: 1.3382 - val_accuracy: 0.8930\n",
      "Epoch 521/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 3.6264e-06 - accuracy: 1.0000 - val_loss: 1.3415 - val_accuracy: 0.8930\n",
      "Epoch 522/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 3.9504e-06 - accuracy: 1.0000 - val_loss: 1.3436 - val_accuracy: 0.8930\n",
      "Epoch 523/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.3696e-06 - accuracy: 1.0000 - val_loss: 1.3457 - val_accuracy: 0.8930\n",
      "Epoch 524/10000\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 4.0678e-06 - accuracy: 1.0000 - val_loss: 1.3485 - val_accuracy: 0.8930\n",
      "Epoch 525/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.4580e-06 - accuracy: 1.0000 - val_loss: 1.3501 - val_accuracy: 0.8930\n",
      "Epoch 526/10000\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 1.7405e-06 - accuracy: 1.0000 - val_loss: 1.3516 - val_accuracy: 0.8930\n",
      "Epoch 527/10000\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 1.5199e-06 - accuracy: 1.0000 - val_loss: 1.3534 - val_accuracy: 0.8930\n"
     ]
    }
   ],
   "source": [
    "# Define the early stopping callback\n",
    "early_stop = EarlyStopping(monitor='loss',\n",
    "                           patience=50, \n",
    "                           start_from_epoch=200) # I leave the first 200 epoch for warmup\n",
    "\n",
    "# run the model on y_train and y_test\n",
    "num_epochs = 10000\n",
    "\n",
    "history = model.fit(padded, \n",
    "                    y_train_arr, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(testing_padded, y_test_arr), \n",
    "                    batch_size=32, \n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract accuracy and loss data for training and validation sets\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
